{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8HxacavH2HL",
        "outputId": "d3f909c6-cfc7-4b2c-b3b0-1620704cd642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word to index: {'deep': 0, 'love': 1, 'learning': 2, 'I': 3}\n",
            "Input indices: [3, 1, 0]\n",
            "Target index: 2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the sentence and map words to indices\n",
        "sentence = [\"I\", \"love\", \"deep\", \"learning\"]\n",
        "word_to_idx = {word: i for i, word in enumerate(set(sentence))}\n",
        "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
        "\n",
        "# Convert words to indices\n",
        "X = [word_to_idx[word] for word in sentence[:-1]]  # input: first 3 words\n",
        "y = word_to_idx[sentence[-1]]                      # target: 4th word\n",
        "\n",
        "print(\"Word to index:\", word_to_idx)\n",
        "print(\"Input indices:\", X)\n",
        "print(\"Target index:\", y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model dimensions\n",
        "vocab_size = len(word_to_idx)\n",
        "hidden_size = 5\n",
        "\n",
        "# Initialize weights and biases\n",
        "np.random.seed(1)\n",
        "W1 = np.random.randn(hidden_size, vocab_size) * 0.01  # input to hidden\n",
        "W2 = np.random.randn(hidden_size, hidden_size) * 0.01  # hidden to hidden\n",
        "W3 = np.random.randn(vocab_size, hidden_size) * 0.01  # hidden to output\n",
        "\n",
        "b1 = np.zeros((hidden_size, 1))  # hidden bias\n",
        "b2 = np.zeros((vocab_size, 1))   # output bias\n",
        "\n",
        "print(\"W1 shape:\", W1.shape)\n",
        "print(\"W2 shape:\", W2.shape)\n",
        "print(\"W3 shape:\", W3.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExnMOnODLV07",
        "outputId": "f246cd81-3e49-4718-c5b6-bb5088447794"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 shape: (5, 4)\n",
            "W2 shape: (5, 5)\n",
            "W3 shape: (4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(index, size):\n",
        "    vec = np.zeros((size, 1))\n",
        "    vec[index] = 1\n",
        "    return vec\n",
        "\n",
        "# Prepare input one-hot vectors\n",
        "inputs = [one_hot(i, vocab_size) for i in X]\n",
        "\n",
        "# Store hidden states\n",
        "h = {}\n",
        "h[-1] = np.zeros((hidden_size, 1))\n",
        "\n",
        "# Forward through time\n",
        "for t in range(len(inputs)):\n",
        "    h[t] = np.tanh(np.dot(W1, inputs[t]) + np.dot(W2, h[t-1]) + b1)\n",
        "    print(f\"Hidden state at time {t}:\\n\", h[t])\n",
        "\n",
        "# Output layer\n",
        "y_out = np.dot(W3, h[len(X)-1]) + b2\n",
        "probs = np.exp(y_out) / np.sum(np.exp(y_out))  # softmax\n",
        "\n",
        "print(\"\\nOutput vector (before softmax):\\n\", y_out)\n",
        "print(\"Predicted probabilities:\\n\", probs.ravel())\n",
        "print(\"Predicted word:\", idx_to_word[np.argmax(probs)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPWex-bULgy1",
        "outputId": "395c3889-4b56-4bcf-ce2d-37c28659b54f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden state at time 0:\n",
            " [[-0.01072927]\n",
            " [-0.00761192]\n",
            " [-0.02059849]\n",
            " [-0.01099847]\n",
            " [ 0.00582809]]\n",
            "Hidden state at time 1:\n",
            " [[-0.00627501]\n",
            " [-0.02267566]\n",
            " [-0.0021939 ]\n",
            " [-0.00394171]\n",
            " [-0.00871949]]\n",
            "Hidden state at time 2:\n",
            " [[ 0.01593346]\n",
            " [ 0.00870947]\n",
            " [ 0.00343067]\n",
            " [-0.00310528]\n",
            " [-0.00156572]]\n",
            "\n",
            "Output vector (before softmax):\n",
            " [[-2.62098862e-05]\n",
            " [-7.92881217e-06]\n",
            " [ 1.75756294e-04]\n",
            " [ 8.12122318e-06]]\n",
            "Predicted probabilities:\n",
            " [0.24998409 0.24998866 0.25003458 0.24999267]\n",
            "Predicted word: learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the target\n",
        "target = one_hot(y, vocab_size)\n",
        "dy = probs - target  # derivative of loss wrt output\n",
        "\n",
        "# Initialize gradients\n",
        "dW3 = np.dot(dy, h[len(X)-1].T)\n",
        "db2 = dy.copy()\n",
        "\n",
        "dW1 = np.zeros_like(W1)\n",
        "dW2 = np.zeros_like(W2)\n",
        "db1 = np.zeros_like(b1)\n",
        "dh_next = np.zeros_like(h[0])\n",
        "\n",
        "# Backpropagation through time\n",
        "for t in reversed(range(len(inputs))):\n",
        "    dh = np.dot(W3.T, dy) + dh_next\n",
        "    dh_raw = (1 - h[t] ** 2) * dh\n",
        "    db1 += dh_raw\n",
        "    dW1 += np.dot(dh_raw, inputs[t].T)\n",
        "    dW2 += np.dot(dh_raw, h[t-1].T)\n",
        "    dh_next = np.dot(W2.T, dh_raw)\n",
        "\n",
        "# Print gradients\n",
        "print(\"\\ndW3:\\n\", dW3)\n",
        "print(\"dW2:\\n\", dW2)\n",
        "print(\"dW1:\\n\", dW1)\n",
        "print(\"db2:\\n\", db2.ravel())\n",
        "print(\"db1:\\n\", db1.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d41FeFK6PVEG",
        "outputId": "1acea5be-2603-47aa-e8af-26e14a9c4c58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dW3:\n",
            " [[ 0.00398311  0.00217723  0.00085761 -0.00077627 -0.0003914 ]\n",
            " [ 0.00398318  0.00217727  0.00085763 -0.00077628 -0.00039141]\n",
            " [-0.01194954 -0.0065318  -0.00257288  0.00232885  0.00117423]\n",
            " [ 0.00398325  0.0021773   0.00085764 -0.0007763  -0.00039142]]\n",
            "dW2:\n",
            " [[1.19738723e-04 2.14804752e-04 1.59669946e-04 1.04994943e-04\n",
            "  2.13781165e-05]\n",
            " [6.04246206e-05 1.07801124e-04 8.08983769e-05 5.30660032e-05\n",
            "  1.03906505e-05]\n",
            " [5.60469284e-05 1.00019430e-04 7.50220464e-05 4.92175566e-05\n",
            "  9.65674055e-06]\n",
            " [6.02296307e-05 1.05783164e-04 8.15402863e-05 5.31230181e-05\n",
            "  9.24566972e-06]\n",
            " [7.57048928e-05 1.33826260e-04 1.02024236e-04 6.66543168e-05\n",
            "  1.21958367e-05]]\n",
            "dW1:\n",
            " [[-0.0071256  -0.0069926   0.         -0.00699357]\n",
            " [-0.00356306 -0.0035479   0.         -0.00354584]\n",
            " [-0.00330648 -0.00328995  0.         -0.00328727]\n",
            " [-0.00345992 -0.00359005  0.         -0.00359284]\n",
            " [-0.00439628 -0.00448476  0.         -0.00448479]]\n",
            "db2:\n",
            " [ 0.24998409  0.24998866 -0.74996542  0.24999267]\n",
            "db1:\n",
            " [-0.02111177 -0.0106568  -0.00988369 -0.01064281 -0.01336583]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient descent step\n",
        "lr = 0.1\n",
        "W1 -= lr * dW1\n",
        "W2 -= lr * dW2\n",
        "W3 -= lr * dW3\n",
        "b1 -= lr * db1\n",
        "b2 -= lr * db2\n",
        "\n",
        "print(\"\\nWeights updated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWJKfuWgPX78",
        "outputId": "ee501c6c-1a60-4998-c815-34caf8faa7b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Weights updated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nUpdated W1:\\n\", W1)\n",
        "print(\"Updated W2:\\n\", W2)\n",
        "print(\"Updated W3:\\n\", W3)\n",
        "print(\"Updated b1:\\n\", b1.ravel())\n",
        "print(\"Updated b2:\\n\", b2.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGyB7A-zPaTZ",
        "outputId": "7c6424a8-98db-4e2a-8274-35a61d604362"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated W1:\n",
            " [[ 0.01695601 -0.0054183  -0.00528172 -0.01003033]\n",
            " [ 0.00901038 -0.0226606   0.01744812 -0.00725748]\n",
            " [ 0.00352104 -0.00216471  0.01462108 -0.02027268]\n",
            " [-0.00287818 -0.00348154  0.01133769 -0.01063963]\n",
            " [-0.00128465 -0.00833011  0.00042214  0.00627663]]\n",
            "Updated W2:\n",
            " [[-0.01101817  0.01142576  0.00899994  0.00501444  0.00900642]\n",
            " [-0.00684332 -0.00123968 -0.00936578 -0.00268419  0.00530252]\n",
            " [-0.00692221 -0.00397754 -0.00687923 -0.00845698 -0.00671343]\n",
            " [-0.00013267 -0.01118368  0.002336    0.01659271  0.00741952]\n",
            " [-0.00192593 -0.00888967 -0.00748179  0.01691788  0.00050686]]\n",
            "Updated W3:\n",
            " [[-0.00676827  0.00169143  0.02091679  0.00127922  0.00621117]\n",
            " [ 0.00260338 -0.00374023 -0.01151094 -0.0034158  -0.0020498 ]\n",
            " [ 0.00706119  0.00904301  0.00956831  0.00262299  0.00873399]\n",
            " [-0.0079423   0.01231095  0.00504353 -0.0029033   0.00492432]]\n",
            "Updated b1:\n",
            " [0.00211118 0.00106568 0.00098837 0.00106428 0.00133658]\n",
            "Updated b2:\n",
            " [-0.02499841 -0.02499887  0.07499654 -0.02499927]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R9CnfahFTlkV"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}